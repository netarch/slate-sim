{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "\n",
    "import simulator as sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = dict({'user_1': 150, \n",
    "               'user_2': 150})\n",
    "\n",
    "# They are meant to be predicted using some model. i.e., linear regression or deep learning\n",
    "class Service:\n",
    "    def __init__(self, name_, svc_t_, m_tput_, plc_):\n",
    "        self.name = name_\n",
    "        self.service_time = svc_t_ # This should be some function(i.e., linear regression, fully connected layer) of something(i.e., load) eventually.\n",
    "        self.max_tput = m_tput_\n",
    "        self.placement = plc_\n",
    "        \n",
    "service_time = dict({\"A\":30.0,\n",
    "                     \"B\":10.0})\n",
    "\n",
    "\n",
    "# maximum amount of requests that can come through a node. Unlimited.\n",
    "# Currently, they are set to be sum of total supply. It means no throughput constraint effectively.\n",
    "# It could be useful later to limit the cross cluster routing.\n",
    "node = dict({'A_start_1': 200, \n",
    "            'A_end_1': 200,\n",
    "\n",
    "            'A_start_2': 200,\n",
    "            'A_end_2': 200,\n",
    "\n",
    "            'B_start_1': 200,\n",
    "            'B_end_1': 200,\n",
    "\n",
    "            'B_start_2': 200,\n",
    "            'B_end_2': 200\n",
    "            })\n",
    "\n",
    "total_num_request = 0\n",
    "for key, value in source.items():\n",
    "    total_num_request += value\n",
    "destination = dict({'dst': total_num_request}) # [user_1 supply] + [user_2 supply]\n",
    "\n",
    "network_latency = dict({\"region\":80.0,\n",
    "                        \"rack\":1.0})\n",
    "\n",
    "\n",
    "# topology: A -> B -> C\n",
    "arcs, cost = gp.multidict({\n",
    "    # user_1: end user connected to cluster 1\n",
    "    # user_2: end user connected to cluster 2\n",
    "    ('user_1', 'A_start_1'): network_latency[\"rack\"],\n",
    "    ('user_2', 'A_start_2'): network_latency[\"rack\"],\n",
    "    ('user_1', 'A_start_2'): network_latency[\"region\"],\n",
    "    ('user_2', 'A_start_1'): network_latency[\"region\"],\n",
    "    \n",
    "    # service time of A, it should be function of something.\n",
    "    ('A_start_1', 'A_end_1'): service_time[\"A\"],\n",
    "    ('A_start_2', 'A_end_2'): service_time[\"A\"],\n",
    "    \n",
    "    # network latency between A and B\n",
    "    ('A_end_1', 'B_start_1'): network_latency[\"rack\"],\n",
    "    ('A_end_2', 'B_start_2'): network_latency[\"rack\"],\n",
    "    ('A_end_1', 'B_start_2'): network_latency[\"region\"],\n",
    "    ('A_end_2', 'B_start_1'): network_latency[\"region\"],\n",
    "    \n",
    "    # service time of B, it should be function of something.\n",
    "    ('B_start_1', 'B_end_1'): service_time[\"B\"],\n",
    "    ('B_start_2', 'B_end_2'): service_time[\"B\"],\n",
    "    \n",
    "    ('B_end_1', 'dst'): 0.0,\n",
    "    ('B_end_2', 'dst'): 0.0,\n",
    "})\n",
    "\n",
    "# # print(type(arcs))\n",
    "# print(\"arcs: \", arcs)\n",
    "# # print(dict(arcs).keys())\n",
    "# # print(type(cost))\n",
    "# print(\"cost: \", cost)\n",
    "\n",
    "model = gp.Model('RequestRouting')\n",
    "flow = model.addVars(arcs, obj=cost, name=\"flow\")\n",
    "\n",
    "# Constraint 1: source\n",
    "src_keys = source.keys()\n",
    "src_flow = model.addConstrs((gp.quicksum(flow.select(src, '*')) == source[src] for src in src_keys), name=\"source\")\n",
    "\n",
    "# Constraint 2: destination\n",
    "dest_keys = destination.keys()\n",
    "dst_flow = model.addConstrs((gp.quicksum(flow.select('*', dst)) == destination[dst] for dst in dest_keys), name=\"destination\")\n",
    "\n",
    "# Constraint 3(could be redundant): total source of source = total destination of destination\n",
    "# sources = source.keys()\n",
    "# dests = destination.keys()\n",
    "# src_dst_flow = model.addConstrs(\n",
    "#     (gp.quicksum(flow.select(s, '*') for s in sources) == \n",
    "#      gp.quicksum(flow.select('*', dst) for dst in dests)),\n",
    "#     name=\"src_and_dest\")\n",
    "\n",
    "# Constraint 3: flow conservation\n",
    "node_key = node.keys()\n",
    "node_flow = model.addConstrs((gp.quicksum(flow.select(n_, '*')) == gp.quicksum(flow.select('*', n_)) for n_ in node_key), name=\"node\")\n",
    "\n",
    "# Constraint 4: max throughput of service\n",
    "node_key = node.keys()\n",
    "throughput = model.addConstrs((gp.quicksum(flow.select('*', n_)) <= node[n_] for n_ in node_key), name=\"service_capacity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 10.0.2 build v10.0.2rc0 (mac64[rosetta2])\n",
      "\n",
      "CPU model: Apple M1 Pro\n",
      "Thread count: 10 physical cores, 10 logical processors, using up to 10 threads\n",
      "\n",
      "Optimize a model with 19 rows, 14 columns and 40 nonzeros\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 8e+01]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e+02, 3e+02]\n",
      "\n",
      "Solved in 0 iterations and 0.01 seconds (0.00 work units)\n",
      "Optimal objective  1.260000000e+04\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>From</th>\n",
       "      <th>To</th>\n",
       "      <th>Flow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_1</td>\n",
       "      <td>A_start_1</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user_2</td>\n",
       "      <td>A_start_2</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A_start_1</td>\n",
       "      <td>A_end_1</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A_start_2</td>\n",
       "      <td>A_end_2</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A_end_1</td>\n",
       "      <td>B_start_1</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A_end_2</td>\n",
       "      <td>B_start_2</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>B_start_1</td>\n",
       "      <td>B_end_1</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>B_start_2</td>\n",
       "      <td>B_end_2</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>B_end_1</td>\n",
       "      <td>dst</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>B_end_2</td>\n",
       "      <td>dst</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        From         To   Flow\n",
       "0     user_1  A_start_1  150.0\n",
       "1     user_2  A_start_2  150.0\n",
       "2  A_start_1    A_end_1  150.0\n",
       "3  A_start_2    A_end_2  150.0\n",
       "4    A_end_1  B_start_1  150.0\n",
       "5    A_end_2  B_start_2  150.0\n",
       "6  B_start_1    B_end_1  150.0\n",
       "7  B_start_2    B_end_2  150.0\n",
       "8    B_end_1        dst  150.0\n",
       "9    B_end_2        dst  150.0"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimize()\n",
    "if model.Status == GRB.INFEASIBLE:\n",
    "    print(\"######################\")\n",
    "    print(\"### INFEASIBLE MODEL!\")\n",
    "    model.computeIIS()\n",
    "    model.write(\"model.ilp\")\n",
    "    # print('\\nThe following constraints and variables are in the IIS:')\n",
    "    # for c in model.getConstrs():\n",
    "    #     if c.IISConstr: print(f'\\t{c.constrname}: {model.getRow(c)} {c.Sense} {c.RHS}')\n",
    "    # for v in model.getVars():\n",
    "    #     if v.IISLB: print(f'\\t{v.varname} ≥ {v.LB}')\n",
    "    #     if v.IISUB: print(f'\\t{v.varname} ≤ {v.UB}')\n",
    "    \n",
    "# if model.Status == GRB.OPTIMAL:\n",
    "#     solution = model.getAttr('X', flow)\n",
    "#     for i, j in arcs:\n",
    "#         if solution[i, j] > 0:\n",
    "#             print('%s -> %s: %g' % (i, j, solution[i, j]))\n",
    "\n",
    "request_flow = pd.DataFrame(columns=[\"From\", \"To\", \"Flow\"])\n",
    "for arc in arcs:\n",
    "    if flow[arc].x > 1e-6:\n",
    "        temp = pd.DataFrame({\"From\": [arc[0]], \"To\": [arc[1]], \"Flow\": [flow[arc].x]})\n",
    "        request_flow = pd.concat([request_flow, temp], ignore_index=True)\n",
    "request_flow\n",
    "         \n",
    "# Simple version of model relax\n",
    "# if model.status == GRB.INFEASIBLE:\n",
    "#     vars = model.getVars()\n",
    "#     ubpen = [1.0]*model.numVars\n",
    "#     model.feasRelax(1, False, vars, None, ubpen, None, None)\n",
    "#     model.optimize()\n",
    "\n",
    "# # Simple version of model relax\n",
    "# if model.status == GRB.INFEASIBLE:\n",
    "#     model.feasRelaxS(1, False, False, True)\n",
    "#     model.optimize()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
